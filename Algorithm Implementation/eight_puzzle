import heapq
import time

class PuzzleState:
    def __init__(self, board, parent=None, move="", g=0, h=0):
        self.board = board
        self.parent = parent
        self.move = move
        self.g = g  # cost so far
        self.h = h  # heuristic
        self.f = g + h  # total estimated cost

    def __lt__(self, other):
        return self.f < other.f

    def get_neighbors(self):
        neighbors = []
        zero_index = self.board.index(0)
        x, y = divmod(zero_index, 3)

        moves = {
            "Up": (x - 1, y),
            "Down": (x + 1, y),
            "Left": (x, y - 1),
            "Right": (x, y + 1),
        }

        for move, (nx, ny) in moves.items():
            if 0 <= nx < 3 and 0 <= ny < 3:
                new_index = nx * 3 + ny
                new_board = self.board[:]
                new_board[zero_index], new_board[new_index] = new_board[new_index], new_board[zero_index]
                neighbors.append(PuzzleState(new_board, self, move, self.g + 1))
        return neighbors

    def path_states(self):
        state, states = self, []
        while state:
            states.append(state)
            state = state.parent
        return states[::-1]  # from start to goal


# Heuristic 1: Misplaced Tiles
def misplaced_tiles(state, goal):
    return sum(1 for i in range(9) if state.board[i] != 0 and state.board[i] != goal[i])


# Heuristic 2: Manhattan Distance
def manhattan_distance(state, goal):
    distance = 0
    for i in range(9):
        if state.board[i] != 0:
            x1, y1 = divmod(i, 3)
            goal_index = goal.index(state.board[i])
            x2, y2 = divmod(goal_index, 3)
            distance += abs(x1 - x2) + abs(y1 - y2)
    return distance


def a_star(start_board, goal_board, heuristic):
    start_state = PuzzleState(start_board, None, "", 0, heuristic(PuzzleState(start_board), goal_board))
    frontier = []
    heapq.heappush(frontier, start_state)
    explored = set()

    while frontier:
        current = heapq.heappop(frontier)
        if current.board == goal_board:
            return current.path_states()

        explored.add(tuple(current.board))

        for neighbor in current.get_neighbors():
            if tuple(neighbor.board) not in explored:
                neighbor.h = heuristic(neighbor, goal_board)
                neighbor.f = neighbor.g + neighbor.h
                heapq.heappush(frontier, neighbor)

    return None


def read_board(prompt):
    print(prompt)
    board = []
    for _ in range(3):
        row = input().split()
        for val in row:
            if val == "-":
                board.append(0)
            else:
                board.append(int(val))
    return board


def print_board(board):
    for i in range(0, 9, 3):
        row = ["-" if x == 0 else str(x) for x in board[i:i+3]]
        print(" ".join(row))
    print()


if __name__ == "__main__":
    start = read_board("Enter the initial state (use '-' for empty):")
    goal = read_board("Enter the goal state (use '-' for empty):")

    print("\nSolving 8-puzzle using Manhattan Distance Heuristic:\n")
    solution = a_star(start, goal, manhattan_distance)

    if solution:
        for step, state in enumerate(solution):
            print(f"Step {step}: {state.move if step > 0 else 'Start'}")
            print_board(state.board)
            time.sleep(0.5)  # delay for animation effect
    else:
        print("No solution found.")
